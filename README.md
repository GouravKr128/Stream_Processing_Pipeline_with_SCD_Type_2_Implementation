## Stream Processing Pipeline with SCD Type 2 Implementation
<br>

### **Overview**
This project demonstrates an end-to-end real-time data engineering pipeline designed to capture, process, and store streaming data while maintaining historical accuracy. By implementing Slowly Changing Dimensions (SCD) Type 2, the pipeline ensures that changes in source data are tracked over time in the Data Warehouse, allowing for accurate "point-in-time" reporting and longitudinal analysis.

### **Tech Stack**
Spark Structured Streaming, Kafka, Azure Event Hubs, Azure Synapse Analytics, Faker, PySpark, Azure Databricks, ADLS Gen2, Key Vault.

### **Description**
